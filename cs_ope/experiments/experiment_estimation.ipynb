{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from experiment_learning import data_generation, behavior_and_evaluation_policy, true_value\n",
    "from kernel_regression import KernelRegression\n",
    "# from cs_ope_estimator import ipw, dm, dr, dml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'pendigits'\n",
    "sample_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.kernel_regression import KernelReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, Y_matrix, train_test_split, classes, N, N_train, N_test = data_generation(data_name,sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(Y_matrix).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b=X.shape\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCL2Layer(b, len(classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0727, 0.0680, 0.0707,  ..., 0.0600, 0.0620, 0.0700],\n",
       "        [0.0727, 0.0680, 0.0707,  ..., 0.0600, 0.0620, 0.0700],\n",
       "        [0.0727, 0.0680, 0.0707,  ..., 0.0600, 0.0620, 0.0700],\n",
       "        ...,\n",
       "        [0.0727, 0.0680, 0.0707,  ..., 0.0600, 0.0620, 0.0700],\n",
       "        [0.0727, 0.0680, 0.0707,  ..., 0.0600, 0.0620, 0.0700],\n",
       "        [0.0727, 0.0680, 0.0707,  ..., 0.0600, 0.0620, 0.0700]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(X)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 10])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10000], Loss: 0.0910\n",
      "Epoch [20/10000], Loss: 0.0909\n",
      "Epoch [30/10000], Loss: 0.0908\n",
      "Epoch [40/10000], Loss: 0.0908\n",
      "Epoch [50/10000], Loss: 0.0907\n",
      "Epoch [60/10000], Loss: 0.0907\n",
      "Epoch [70/10000], Loss: 0.0906\n",
      "Epoch [80/10000], Loss: 0.0906\n",
      "Epoch [90/10000], Loss: 0.0906\n",
      "Epoch [100/10000], Loss: 0.0905\n",
      "Epoch [110/10000], Loss: 0.0905\n",
      "Epoch [120/10000], Loss: 0.0905\n",
      "Epoch [130/10000], Loss: 0.0905\n",
      "Epoch [140/10000], Loss: 0.0905\n",
      "Epoch [150/10000], Loss: 0.0905\n",
      "Epoch [160/10000], Loss: 0.0904\n",
      "Epoch [170/10000], Loss: 0.0904\n",
      "Epoch [180/10000], Loss: 0.0904\n",
      "Epoch [190/10000], Loss: 0.0904\n",
      "Epoch [200/10000], Loss: 0.0904\n",
      "Epoch [210/10000], Loss: 0.0904\n",
      "Epoch [220/10000], Loss: 0.0904\n",
      "Epoch [230/10000], Loss: 0.0904\n",
      "Epoch [240/10000], Loss: 0.0904\n",
      "Epoch [250/10000], Loss: 0.0904\n",
      "Epoch [260/10000], Loss: 0.0904\n",
      "Epoch [270/10000], Loss: 0.0904\n",
      "Epoch [280/10000], Loss: 0.0904\n",
      "Epoch [290/10000], Loss: 0.0904\n",
      "Epoch [300/10000], Loss: 0.0904\n",
      "Epoch [310/10000], Loss: 0.0904\n",
      "Epoch [320/10000], Loss: 0.0904\n",
      "Epoch [330/10000], Loss: 0.0904\n",
      "Epoch [340/10000], Loss: 0.0904\n",
      "Epoch [350/10000], Loss: 0.0904\n",
      "Epoch [360/10000], Loss: 0.0904\n",
      "Epoch [370/10000], Loss: 0.0904\n",
      "Epoch [380/10000], Loss: 0.0904\n",
      "Epoch [390/10000], Loss: 0.0904\n",
      "Epoch [400/10000], Loss: 0.0904\n",
      "Epoch [410/10000], Loss: 0.0904\n",
      "Epoch [420/10000], Loss: 0.0904\n",
      "Epoch [430/10000], Loss: 0.0904\n",
      "Epoch [440/10000], Loss: 0.0904\n",
      "Epoch [450/10000], Loss: 0.0904\n",
      "Epoch [460/10000], Loss: 0.0904\n",
      "Epoch [470/10000], Loss: 0.0904\n",
      "Epoch [480/10000], Loss: 0.0904\n",
      "Epoch [490/10000], Loss: 0.0904\n",
      "Epoch [500/10000], Loss: 0.0904\n",
      "Epoch [510/10000], Loss: 0.0904\n",
      "Epoch [520/10000], Loss: 0.0904\n",
      "Epoch [530/10000], Loss: 0.0904\n",
      "Epoch [540/10000], Loss: 0.0904\n",
      "Epoch [550/10000], Loss: 0.0904\n",
      "Epoch [560/10000], Loss: 0.0904\n",
      "Epoch [570/10000], Loss: 0.0904\n",
      "Epoch [580/10000], Loss: 0.0904\n",
      "Epoch [590/10000], Loss: 0.0904\n",
      "Epoch [600/10000], Loss: 0.0904\n",
      "Epoch [610/10000], Loss: 0.0904\n",
      "Epoch [620/10000], Loss: 0.0904\n",
      "Epoch [630/10000], Loss: 0.0904\n",
      "Epoch [640/10000], Loss: 0.0904\n",
      "Epoch [650/10000], Loss: 0.0904\n",
      "Epoch [660/10000], Loss: 0.0904\n",
      "Epoch [670/10000], Loss: 0.0904\n",
      "Epoch [680/10000], Loss: 0.0904\n",
      "Epoch [690/10000], Loss: 0.0904\n",
      "Epoch [700/10000], Loss: 0.0904\n",
      "Epoch [710/10000], Loss: 0.0904\n",
      "Epoch [720/10000], Loss: 0.0904\n",
      "Epoch [730/10000], Loss: 0.0904\n",
      "Epoch [740/10000], Loss: 0.0904\n",
      "Epoch [750/10000], Loss: 0.0904\n",
      "Epoch [760/10000], Loss: 0.0904\n",
      "Epoch [770/10000], Loss: 0.0904\n",
      "Epoch [780/10000], Loss: 0.0904\n",
      "Epoch [790/10000], Loss: 0.0904\n",
      "Epoch [800/10000], Loss: 0.0904\n",
      "Epoch [810/10000], Loss: 0.0904\n",
      "Epoch [820/10000], Loss: 0.0904\n",
      "Epoch [830/10000], Loss: 0.0904\n",
      "Epoch [840/10000], Loss: 0.0904\n",
      "Epoch [850/10000], Loss: 0.0904\n",
      "Epoch [860/10000], Loss: 0.0904\n",
      "Epoch [870/10000], Loss: 0.0904\n",
      "Epoch [880/10000], Loss: 0.0904\n",
      "Epoch [890/10000], Loss: 0.0904\n",
      "Epoch [900/10000], Loss: 0.0904\n",
      "Epoch [910/10000], Loss: 0.0904\n",
      "Epoch [920/10000], Loss: 0.0904\n",
      "Epoch [930/10000], Loss: 0.0904\n",
      "Epoch [940/10000], Loss: 0.0904\n",
      "Epoch [950/10000], Loss: 0.0904\n",
      "Epoch [960/10000], Loss: 0.0904\n",
      "Epoch [970/10000], Loss: 0.0904\n",
      "Epoch [980/10000], Loss: 0.0904\n",
      "Epoch [990/10000], Loss: 0.0904\n",
      "Epoch [1000/10000], Loss: 0.0904\n",
      "Epoch [1010/10000], Loss: 0.0904\n",
      "Epoch [1020/10000], Loss: 0.0904\n",
      "Epoch [1030/10000], Loss: 0.0904\n",
      "Epoch [1040/10000], Loss: 0.0904\n",
      "Epoch [1050/10000], Loss: 0.0904\n",
      "Epoch [1060/10000], Loss: 0.0904\n",
      "Epoch [1070/10000], Loss: 0.0904\n",
      "Epoch [1080/10000], Loss: 0.0904\n",
      "Epoch [1090/10000], Loss: 0.0904\n",
      "Epoch [1100/10000], Loss: 0.0904\n",
      "Epoch [1110/10000], Loss: 0.0904\n",
      "Epoch [1120/10000], Loss: 0.0904\n",
      "Epoch [1130/10000], Loss: 0.0904\n",
      "Epoch [1140/10000], Loss: 0.0904\n",
      "Epoch [1150/10000], Loss: 0.0904\n",
      "Epoch [1160/10000], Loss: 0.0904\n",
      "Epoch [1170/10000], Loss: 0.0904\n",
      "Epoch [1180/10000], Loss: 0.0904\n",
      "Epoch [1190/10000], Loss: 0.0904\n",
      "Epoch [1200/10000], Loss: 0.0904\n",
      "Epoch [1210/10000], Loss: 0.0904\n",
      "Epoch [1220/10000], Loss: 0.0904\n",
      "Epoch [1230/10000], Loss: 0.0904\n",
      "Epoch [1240/10000], Loss: 0.0904\n",
      "Epoch [1250/10000], Loss: 0.0904\n",
      "Epoch [1260/10000], Loss: 0.0904\n",
      "Epoch [1270/10000], Loss: 0.0904\n",
      "Epoch [1280/10000], Loss: 0.0904\n",
      "Epoch [1290/10000], Loss: 0.0904\n",
      "Epoch [1300/10000], Loss: 0.0904\n",
      "Epoch [1310/10000], Loss: 0.0904\n",
      "Epoch [1320/10000], Loss: 0.0904\n",
      "Epoch [1330/10000], Loss: 0.0904\n",
      "Epoch [1340/10000], Loss: 0.0904\n",
      "Epoch [1350/10000], Loss: 0.0904\n",
      "Epoch [1360/10000], Loss: 0.0904\n",
      "Epoch [1370/10000], Loss: 0.0904\n",
      "Epoch [1380/10000], Loss: 0.0904\n",
      "Epoch [1390/10000], Loss: 0.0904\n",
      "Epoch [1400/10000], Loss: 0.0904\n",
      "Epoch [1410/10000], Loss: 0.0904\n",
      "Epoch [1420/10000], Loss: 0.0904\n",
      "Epoch [1430/10000], Loss: 0.0904\n",
      "Epoch [1440/10000], Loss: 0.0904\n",
      "Epoch [1450/10000], Loss: 0.0904\n",
      "Epoch [1460/10000], Loss: 0.0904\n",
      "Epoch [1470/10000], Loss: 0.0904\n",
      "Epoch [1480/10000], Loss: 0.0904\n",
      "Epoch [1490/10000], Loss: 0.0904\n",
      "Epoch [1500/10000], Loss: 0.0904\n",
      "Epoch [1510/10000], Loss: 0.0904\n",
      "Epoch [1520/10000], Loss: 0.0904\n",
      "Epoch [1530/10000], Loss: 0.0904\n",
      "Epoch [1540/10000], Loss: 0.0904\n",
      "Epoch [1550/10000], Loss: 0.0904\n",
      "Epoch [1560/10000], Loss: 0.0904\n",
      "Epoch [1570/10000], Loss: 0.0904\n",
      "Epoch [1580/10000], Loss: 0.0904\n",
      "Epoch [1590/10000], Loss: 0.0904\n",
      "Epoch [1600/10000], Loss: 0.0904\n",
      "Epoch [1610/10000], Loss: 0.0904\n",
      "Epoch [1620/10000], Loss: 0.0904\n",
      "Epoch [1630/10000], Loss: 0.0904\n",
      "Epoch [1640/10000], Loss: 0.0904\n",
      "Epoch [1650/10000], Loss: 0.0904\n",
      "Epoch [1660/10000], Loss: 0.0904\n",
      "Epoch [1670/10000], Loss: 0.0904\n",
      "Epoch [1680/10000], Loss: 0.0904\n",
      "Epoch [1690/10000], Loss: 0.0904\n",
      "Epoch [1700/10000], Loss: 0.0904\n",
      "Epoch [1710/10000], Loss: 0.0904\n",
      "Epoch [1720/10000], Loss: 0.0904\n",
      "Epoch [1730/10000], Loss: 0.0904\n",
      "Epoch [1740/10000], Loss: 0.0904\n",
      "Epoch [1750/10000], Loss: 0.0904\n",
      "Epoch [1760/10000], Loss: 0.0904\n",
      "Epoch [1770/10000], Loss: 0.0904\n",
      "Epoch [1780/10000], Loss: 0.0904\n",
      "Epoch [1790/10000], Loss: 0.0904\n",
      "Epoch [1800/10000], Loss: 0.0904\n",
      "Epoch [1810/10000], Loss: 0.0904\n",
      "Epoch [1820/10000], Loss: 0.0904\n",
      "Epoch [1830/10000], Loss: 0.0904\n",
      "Epoch [1840/10000], Loss: 0.0904\n",
      "Epoch [1850/10000], Loss: 0.0904\n",
      "Epoch [1860/10000], Loss: 0.0904\n",
      "Epoch [1870/10000], Loss: 0.0904\n",
      "Epoch [1880/10000], Loss: 0.0904\n",
      "Epoch [1890/10000], Loss: 0.0904\n",
      "Epoch [1900/10000], Loss: 0.0904\n",
      "Epoch [1910/10000], Loss: 0.0904\n",
      "Epoch [1920/10000], Loss: 0.0904\n",
      "Epoch [1930/10000], Loss: 0.0904\n",
      "Epoch [1940/10000], Loss: 0.0904\n",
      "Epoch [1950/10000], Loss: 0.0904\n",
      "Epoch [1960/10000], Loss: 0.0904\n",
      "Epoch [1970/10000], Loss: 0.0904\n",
      "Epoch [1980/10000], Loss: 0.0904\n",
      "Epoch [1990/10000], Loss: 0.0904\n",
      "Epoch [2000/10000], Loss: 0.0904\n",
      "Epoch [2010/10000], Loss: 0.0904\n",
      "Epoch [2020/10000], Loss: 0.0904\n",
      "Epoch [2030/10000], Loss: 0.0904\n",
      "Epoch [2040/10000], Loss: 0.0904\n",
      "Epoch [2050/10000], Loss: 0.0904\n",
      "Epoch [2060/10000], Loss: 0.0904\n",
      "Epoch [2070/10000], Loss: 0.0904\n",
      "Epoch [2080/10000], Loss: 0.0904\n",
      "Epoch [2090/10000], Loss: 0.0904\n",
      "Epoch [2100/10000], Loss: 0.0904\n",
      "Epoch [2110/10000], Loss: 0.0904\n",
      "Epoch [2120/10000], Loss: 0.0904\n",
      "Epoch [2130/10000], Loss: 0.0904\n",
      "Epoch [2140/10000], Loss: 0.0904\n",
      "Epoch [2150/10000], Loss: 0.0904\n",
      "Epoch [2160/10000], Loss: 0.0904\n",
      "Epoch [2170/10000], Loss: 0.0904\n",
      "Epoch [2180/10000], Loss: 0.0904\n",
      "Epoch [2190/10000], Loss: 0.0904\n",
      "Epoch [2200/10000], Loss: 0.0904\n",
      "Epoch [2210/10000], Loss: 0.0904\n",
      "Epoch [2220/10000], Loss: 0.0904\n",
      "Epoch [2230/10000], Loss: 0.0904\n",
      "Epoch [2240/10000], Loss: 0.0904\n",
      "Epoch [2250/10000], Loss: 0.0904\n",
      "Epoch [2260/10000], Loss: 0.0904\n",
      "Epoch [2270/10000], Loss: 0.0904\n",
      "Epoch [2280/10000], Loss: 0.0904\n",
      "Epoch [2290/10000], Loss: 0.0904\n",
      "Epoch [2300/10000], Loss: 0.0904\n",
      "Epoch [2310/10000], Loss: 0.0904\n",
      "Epoch [2320/10000], Loss: 0.0904\n",
      "Epoch [2330/10000], Loss: 0.0904\n",
      "Epoch [2340/10000], Loss: 0.0904\n",
      "Epoch [2350/10000], Loss: 0.0904\n",
      "Epoch [2360/10000], Loss: 0.0904\n",
      "Epoch [2370/10000], Loss: 0.0904\n",
      "Epoch [2380/10000], Loss: 0.0904\n",
      "Epoch [2390/10000], Loss: 0.0904\n",
      "Epoch [2400/10000], Loss: 0.0904\n",
      "Epoch [2410/10000], Loss: 0.0904\n",
      "Epoch [2420/10000], Loss: 0.0904\n",
      "Epoch [2430/10000], Loss: 0.0904\n",
      "Epoch [2440/10000], Loss: 0.0904\n",
      "Epoch [2450/10000], Loss: 0.0904\n",
      "Epoch [2460/10000], Loss: 0.0904\n",
      "Epoch [2470/10000], Loss: 0.0904\n",
      "Epoch [2480/10000], Loss: 0.0904\n",
      "Epoch [2490/10000], Loss: 0.0904\n",
      "Epoch [2500/10000], Loss: 0.0904\n",
      "Epoch [2510/10000], Loss: 0.0904\n",
      "Epoch [2520/10000], Loss: 0.0904\n",
      "Epoch [2530/10000], Loss: 0.0904\n",
      "Epoch [2540/10000], Loss: 0.0904\n",
      "Epoch [2550/10000], Loss: 0.0904\n",
      "Epoch [2560/10000], Loss: 0.0904\n",
      "Epoch [2570/10000], Loss: 0.0904\n",
      "Epoch [2580/10000], Loss: 0.0904\n",
      "Epoch [2590/10000], Loss: 0.0904\n",
      "Epoch [2600/10000], Loss: 0.0904\n",
      "Epoch [2610/10000], Loss: 0.0904\n",
      "Epoch [2620/10000], Loss: 0.0904\n",
      "Epoch [2630/10000], Loss: 0.0904\n",
      "Epoch [2640/10000], Loss: 0.0904\n",
      "Epoch [2650/10000], Loss: 0.0904\n",
      "Epoch [2660/10000], Loss: 0.0904\n",
      "Epoch [2670/10000], Loss: 0.0904\n",
      "Epoch [2680/10000], Loss: 0.0904\n",
      "Epoch [2690/10000], Loss: 0.0904\n",
      "Epoch [2700/10000], Loss: 0.0904\n",
      "Epoch [2710/10000], Loss: 0.0904\n",
      "Epoch [2720/10000], Loss: 0.0904\n",
      "Epoch [2730/10000], Loss: 0.0904\n",
      "Epoch [2740/10000], Loss: 0.0904\n",
      "Epoch [2750/10000], Loss: 0.0904\n",
      "Epoch [2760/10000], Loss: 0.0904\n",
      "Epoch [2770/10000], Loss: 0.0904\n",
      "Epoch [2780/10000], Loss: 0.0904\n",
      "Epoch [2790/10000], Loss: 0.0904\n",
      "Epoch [2800/10000], Loss: 0.0904\n",
      "Epoch [2810/10000], Loss: 0.0904\n",
      "Epoch [2820/10000], Loss: 0.0904\n",
      "Epoch [2830/10000], Loss: 0.0904\n",
      "Epoch [2840/10000], Loss: 0.0904\n",
      "Epoch [2850/10000], Loss: 0.0904\n",
      "Epoch [2860/10000], Loss: 0.0904\n",
      "Epoch [2870/10000], Loss: 0.0904\n",
      "Epoch [2880/10000], Loss: 0.0904\n",
      "Epoch [2890/10000], Loss: 0.0904\n",
      "Epoch [2900/10000], Loss: 0.0904\n",
      "Epoch [2910/10000], Loss: 0.0904\n",
      "Epoch [2920/10000], Loss: 0.0904\n",
      "Epoch [2930/10000], Loss: 0.0904\n",
      "Epoch [2940/10000], Loss: 0.0904\n",
      "Epoch [2950/10000], Loss: 0.0904\n",
      "Epoch [2960/10000], Loss: 0.0904\n",
      "Epoch [2970/10000], Loss: 0.0904\n",
      "Epoch [2980/10000], Loss: 0.0904\n",
      "Epoch [2990/10000], Loss: 0.0904\n",
      "Epoch [3000/10000], Loss: 0.0904\n",
      "Epoch [3010/10000], Loss: 0.0904\n",
      "Epoch [3020/10000], Loss: 0.0904\n",
      "Epoch [3030/10000], Loss: 0.0904\n",
      "Epoch [3040/10000], Loss: 0.0904\n",
      "Epoch [3050/10000], Loss: 0.0904\n",
      "Epoch [3060/10000], Loss: 0.0904\n",
      "Epoch [3070/10000], Loss: 0.0904\n",
      "Epoch [3080/10000], Loss: 0.0904\n",
      "Epoch [3090/10000], Loss: 0.0904\n",
      "Epoch [3100/10000], Loss: 0.0904\n",
      "Epoch [3110/10000], Loss: 0.0904\n",
      "Epoch [3120/10000], Loss: 0.0904\n",
      "Epoch [3130/10000], Loss: 0.0904\n",
      "Epoch [3140/10000], Loss: 0.0904\n",
      "Epoch [3150/10000], Loss: 0.0904\n",
      "Epoch [3160/10000], Loss: 0.0904\n",
      "Epoch [3170/10000], Loss: 0.0904\n",
      "Epoch [3180/10000], Loss: 0.0904\n",
      "Epoch [3190/10000], Loss: 0.0904\n",
      "Epoch [3200/10000], Loss: 0.0904\n",
      "Epoch [3210/10000], Loss: 0.0904\n",
      "Epoch [3220/10000], Loss: 0.0904\n",
      "Epoch [3230/10000], Loss: 0.0904\n",
      "Epoch [3240/10000], Loss: 0.0904\n",
      "Epoch [3250/10000], Loss: 0.0904\n",
      "Epoch [3260/10000], Loss: 0.0904\n",
      "Epoch [3270/10000], Loss: 0.0904\n",
      "Epoch [3280/10000], Loss: 0.0904\n",
      "Epoch [3290/10000], Loss: 0.0904\n",
      "Epoch [3300/10000], Loss: 0.0904\n",
      "Epoch [3310/10000], Loss: 0.0904\n",
      "Epoch [3320/10000], Loss: 0.0904\n",
      "Epoch [3330/10000], Loss: 0.0904\n",
      "Epoch [3340/10000], Loss: 0.0904\n",
      "Epoch [3350/10000], Loss: 0.0904\n",
      "Epoch [3360/10000], Loss: 0.0904\n",
      "Epoch [3370/10000], Loss: 0.0904\n",
      "Epoch [3380/10000], Loss: 0.0904\n",
      "Epoch [3390/10000], Loss: 0.0904\n",
      "Epoch [3400/10000], Loss: 0.0904\n",
      "Epoch [3410/10000], Loss: 0.0904\n",
      "Epoch [3420/10000], Loss: 0.0904\n",
      "Epoch [3430/10000], Loss: 0.0904\n",
      "Epoch [3440/10000], Loss: 0.0904\n",
      "Epoch [3450/10000], Loss: 0.0904\n",
      "Epoch [3460/10000], Loss: 0.0904\n",
      "Epoch [3470/10000], Loss: 0.0904\n",
      "Epoch [3480/10000], Loss: 0.0904\n",
      "Epoch [3490/10000], Loss: 0.0904\n",
      "Epoch [3500/10000], Loss: 0.0904\n",
      "Epoch [3510/10000], Loss: 0.0904\n",
      "Epoch [3520/10000], Loss: 0.0904\n",
      "Epoch [3530/10000], Loss: 0.0904\n",
      "Epoch [3540/10000], Loss: 0.0904\n",
      "Epoch [3550/10000], Loss: 0.0904\n",
      "Epoch [3560/10000], Loss: 0.0904\n",
      "Epoch [3570/10000], Loss: 0.0904\n",
      "Epoch [3580/10000], Loss: 0.0904\n",
      "Epoch [3590/10000], Loss: 0.0904\n",
      "Epoch [3600/10000], Loss: 0.0904\n",
      "Epoch [3610/10000], Loss: 0.0904\n",
      "Epoch [3620/10000], Loss: 0.0904\n",
      "Epoch [3630/10000], Loss: 0.0904\n",
      "Epoch [3640/10000], Loss: 0.0904\n",
      "Epoch [3650/10000], Loss: 0.0904\n",
      "Epoch [3660/10000], Loss: 0.0904\n",
      "Epoch [3670/10000], Loss: 0.0904\n",
      "Epoch [3680/10000], Loss: 0.0904\n",
      "Epoch [3690/10000], Loss: 0.0904\n",
      "Epoch [3700/10000], Loss: 0.0904\n",
      "Epoch [3710/10000], Loss: 0.0904\n",
      "Epoch [3720/10000], Loss: 0.0904\n",
      "Epoch [3730/10000], Loss: 0.0904\n",
      "Epoch [3740/10000], Loss: 0.0904\n",
      "Epoch [3750/10000], Loss: 0.0904\n",
      "Epoch [3760/10000], Loss: 0.0904\n",
      "Epoch [3770/10000], Loss: 0.0904\n",
      "Epoch [3780/10000], Loss: 0.0904\n",
      "Epoch [3790/10000], Loss: 0.0904\n",
      "Epoch [3800/10000], Loss: 0.0904\n",
      "Epoch [3810/10000], Loss: 0.0904\n",
      "Epoch [3820/10000], Loss: 0.0904\n",
      "Epoch [3830/10000], Loss: 0.0904\n",
      "Epoch [3840/10000], Loss: 0.0904\n",
      "Epoch [3850/10000], Loss: 0.0904\n",
      "Epoch [3860/10000], Loss: 0.0904\n",
      "Epoch [3870/10000], Loss: 0.0904\n",
      "Epoch [3880/10000], Loss: 0.0904\n",
      "Epoch [3890/10000], Loss: 0.0904\n",
      "Epoch [3900/10000], Loss: 0.0904\n",
      "Epoch [3910/10000], Loss: 0.0904\n",
      "Epoch [3920/10000], Loss: 0.0904\n",
      "Epoch [3930/10000], Loss: 0.0904\n",
      "Epoch [3940/10000], Loss: 0.0904\n",
      "Epoch [3950/10000], Loss: 0.0904\n",
      "Epoch [3960/10000], Loss: 0.0904\n",
      "Epoch [3970/10000], Loss: 0.0904\n",
      "Epoch [3980/10000], Loss: 0.0904\n",
      "Epoch [3990/10000], Loss: 0.0904\n",
      "Epoch [4000/10000], Loss: 0.0904\n",
      "Epoch [4010/10000], Loss: 0.0904\n",
      "Epoch [4020/10000], Loss: 0.0904\n",
      "Epoch [4030/10000], Loss: 0.0904\n",
      "Epoch [4040/10000], Loss: 0.0904\n",
      "Epoch [4050/10000], Loss: 0.0904\n",
      "Epoch [4060/10000], Loss: 0.0904\n",
      "Epoch [4070/10000], Loss: 0.0904\n",
      "Epoch [4080/10000], Loss: 0.0904\n",
      "Epoch [4090/10000], Loss: 0.0904\n",
      "Epoch [4100/10000], Loss: 0.0904\n",
      "Epoch [4110/10000], Loss: 0.0904\n",
      "Epoch [4120/10000], Loss: 0.0904\n",
      "Epoch [4130/10000], Loss: 0.0904\n",
      "Epoch [4140/10000], Loss: 0.0904\n",
      "Epoch [4150/10000], Loss: 0.0904\n",
      "Epoch [4160/10000], Loss: 0.0904\n",
      "Epoch [4170/10000], Loss: 0.0904\n",
      "Epoch [4180/10000], Loss: 0.0904\n",
      "Epoch [4190/10000], Loss: 0.0904\n",
      "Epoch [4200/10000], Loss: 0.0904\n",
      "Epoch [4210/10000], Loss: 0.0904\n",
      "Epoch [4220/10000], Loss: 0.0904\n",
      "Epoch [4230/10000], Loss: 0.0904\n",
      "Epoch [4240/10000], Loss: 0.0904\n",
      "Epoch [4250/10000], Loss: 0.0904\n",
      "Epoch [4260/10000], Loss: 0.0904\n",
      "Epoch [4270/10000], Loss: 0.0904\n",
      "Epoch [4280/10000], Loss: 0.0904\n",
      "Epoch [4290/10000], Loss: 0.0904\n",
      "Epoch [4300/10000], Loss: 0.0904\n",
      "Epoch [4310/10000], Loss: 0.0904\n",
      "Epoch [4320/10000], Loss: 0.0904\n",
      "Epoch [4330/10000], Loss: 0.0904\n",
      "Epoch [4340/10000], Loss: 0.0904\n",
      "Epoch [4350/10000], Loss: 0.0904\n",
      "Epoch [4360/10000], Loss: 0.0904\n",
      "Epoch [4370/10000], Loss: 0.0904\n",
      "Epoch [4380/10000], Loss: 0.0904\n",
      "Epoch [4390/10000], Loss: 0.0904\n",
      "Epoch [4400/10000], Loss: 0.0904\n",
      "Epoch [4410/10000], Loss: 0.0904\n",
      "Epoch [4420/10000], Loss: 0.0904\n",
      "Epoch [4430/10000], Loss: 0.0904\n",
      "Epoch [4440/10000], Loss: 0.0904\n",
      "Epoch [4450/10000], Loss: 0.0904\n",
      "Epoch [4460/10000], Loss: 0.0904\n",
      "Epoch [4470/10000], Loss: 0.0904\n",
      "Epoch [4480/10000], Loss: 0.0904\n",
      "Epoch [4490/10000], Loss: 0.0904\n",
      "Epoch [4500/10000], Loss: 0.0904\n",
      "Epoch [4510/10000], Loss: 0.0904\n",
      "Epoch [4520/10000], Loss: 0.0904\n",
      "Epoch [4530/10000], Loss: 0.0904\n",
      "Epoch [4540/10000], Loss: 0.0904\n",
      "Epoch [4550/10000], Loss: 0.0904\n",
      "Epoch [4560/10000], Loss: 0.0904\n",
      "Epoch [4570/10000], Loss: 0.0904\n",
      "Epoch [4580/10000], Loss: 0.0904\n",
      "Epoch [4590/10000], Loss: 0.0904\n",
      "Epoch [4600/10000], Loss: 0.0904\n",
      "Epoch [4610/10000], Loss: 0.0904\n",
      "Epoch [4620/10000], Loss: 0.0904\n",
      "Epoch [4630/10000], Loss: 0.0904\n",
      "Epoch [4640/10000], Loss: 0.0904\n",
      "Epoch [4650/10000], Loss: 0.0904\n",
      "Epoch [4660/10000], Loss: 0.0904\n",
      "Epoch [4670/10000], Loss: 0.0904\n",
      "Epoch [4680/10000], Loss: 0.0904\n",
      "Epoch [4690/10000], Loss: 0.0904\n",
      "Epoch [4700/10000], Loss: 0.0904\n",
      "Epoch [4710/10000], Loss: 0.0904\n",
      "Epoch [4720/10000], Loss: 0.0904\n",
      "Epoch [4730/10000], Loss: 0.0904\n",
      "Epoch [4740/10000], Loss: 0.0904\n",
      "Epoch [4750/10000], Loss: 0.0904\n",
      "Epoch [4760/10000], Loss: 0.0904\n",
      "Epoch [4770/10000], Loss: 0.0904\n",
      "Epoch [4780/10000], Loss: 0.0904\n",
      "Epoch [4790/10000], Loss: 0.0904\n",
      "Epoch [4800/10000], Loss: 0.0904\n",
      "Epoch [4810/10000], Loss: 0.0904\n",
      "Epoch [4820/10000], Loss: 0.0904\n",
      "Epoch [4830/10000], Loss: 0.0904\n",
      "Epoch [4840/10000], Loss: 0.0904\n",
      "Epoch [4850/10000], Loss: 0.0904\n",
      "Epoch [4860/10000], Loss: 0.0904\n",
      "Epoch [4870/10000], Loss: 0.0904\n",
      "Epoch [4880/10000], Loss: 0.0904\n",
      "Epoch [4890/10000], Loss: 0.0904\n",
      "Epoch [4900/10000], Loss: 0.0904\n",
      "Epoch [4910/10000], Loss: 0.0904\n",
      "Epoch [4920/10000], Loss: 0.0904\n",
      "Epoch [4930/10000], Loss: 0.0904\n",
      "Epoch [4940/10000], Loss: 0.0904\n",
      "Epoch [4950/10000], Loss: 0.0904\n",
      "Epoch [4960/10000], Loss: 0.0904\n",
      "Epoch [4970/10000], Loss: 0.0904\n",
      "Epoch [4980/10000], Loss: 0.0904\n",
      "Epoch [4990/10000], Loss: 0.0904\n",
      "Epoch [5000/10000], Loss: 0.0904\n",
      "Epoch [5010/10000], Loss: 0.0904\n",
      "Epoch [5020/10000], Loss: 0.0904\n",
      "Epoch [5030/10000], Loss: 0.0904\n",
      "Epoch [5040/10000], Loss: 0.0904\n",
      "Epoch [5050/10000], Loss: 0.0904\n",
      "Epoch [5060/10000], Loss: 0.0904\n",
      "Epoch [5070/10000], Loss: 0.0904\n",
      "Epoch [5080/10000], Loss: 0.0904\n",
      "Epoch [5090/10000], Loss: 0.0904\n",
      "Epoch [5100/10000], Loss: 0.0904\n",
      "Epoch [5110/10000], Loss: 0.0904\n",
      "Epoch [5120/10000], Loss: 0.0904\n",
      "Epoch [5130/10000], Loss: 0.0904\n",
      "Epoch [5140/10000], Loss: 0.0904\n",
      "Epoch [5150/10000], Loss: 0.0904\n",
      "Epoch [5160/10000], Loss: 0.0904\n",
      "Epoch [5170/10000], Loss: 0.0904\n",
      "Epoch [5180/10000], Loss: 0.0904\n",
      "Epoch [5190/10000], Loss: 0.0904\n",
      "Epoch [5200/10000], Loss: 0.0904\n",
      "Epoch [5210/10000], Loss: 0.0904\n",
      "Epoch [5220/10000], Loss: 0.0904\n",
      "Epoch [5230/10000], Loss: 0.0904\n",
      "Epoch [5240/10000], Loss: 0.0904\n",
      "Epoch [5250/10000], Loss: 0.0904\n",
      "Epoch [5260/10000], Loss: 0.0904\n",
      "Epoch [5270/10000], Loss: 0.0904\n",
      "Epoch [5280/10000], Loss: 0.0904\n",
      "Epoch [5290/10000], Loss: 0.0904\n",
      "Epoch [5300/10000], Loss: 0.0904\n",
      "Epoch [5310/10000], Loss: 0.0904\n",
      "Epoch [5320/10000], Loss: 0.0904\n",
      "Epoch [5330/10000], Loss: 0.0904\n",
      "Epoch [5340/10000], Loss: 0.0904\n",
      "Epoch [5350/10000], Loss: 0.0904\n",
      "Epoch [5360/10000], Loss: 0.0904\n",
      "Epoch [5370/10000], Loss: 0.0904\n",
      "Epoch [5380/10000], Loss: 0.0904\n",
      "Epoch [5390/10000], Loss: 0.0904\n",
      "Epoch [5400/10000], Loss: 0.0904\n",
      "Epoch [5410/10000], Loss: 0.0904\n",
      "Epoch [5420/10000], Loss: 0.0904\n",
      "Epoch [5430/10000], Loss: 0.0904\n",
      "Epoch [5440/10000], Loss: 0.0904\n",
      "Epoch [5450/10000], Loss: 0.0904\n",
      "Epoch [5460/10000], Loss: 0.0904\n",
      "Epoch [5470/10000], Loss: 0.0904\n",
      "Epoch [5480/10000], Loss: 0.0904\n",
      "Epoch [5490/10000], Loss: 0.0904\n",
      "Epoch [5500/10000], Loss: 0.0904\n",
      "Epoch [5510/10000], Loss: 0.0904\n",
      "Epoch [5520/10000], Loss: 0.0904\n",
      "Epoch [5530/10000], Loss: 0.0904\n",
      "Epoch [5540/10000], Loss: 0.0904\n",
      "Epoch [5550/10000], Loss: 0.0904\n",
      "Epoch [5560/10000], Loss: 0.0904\n",
      "Epoch [5570/10000], Loss: 0.0904\n",
      "Epoch [5580/10000], Loss: 0.0904\n",
      "Epoch [5590/10000], Loss: 0.0904\n",
      "Epoch [5600/10000], Loss: 0.0904\n",
      "Epoch [5610/10000], Loss: 0.0904\n",
      "Epoch [5620/10000], Loss: 0.0904\n",
      "Epoch [5630/10000], Loss: 0.0904\n",
      "Epoch [5640/10000], Loss: 0.0904\n",
      "Epoch [5650/10000], Loss: 0.0904\n",
      "Epoch [5660/10000], Loss: 0.0904\n",
      "Epoch [5670/10000], Loss: 0.0904\n",
      "Epoch [5680/10000], Loss: 0.0904\n",
      "Epoch [5690/10000], Loss: 0.0904\n",
      "Epoch [5700/10000], Loss: 0.0904\n",
      "Epoch [5710/10000], Loss: 0.0904\n",
      "Epoch [5720/10000], Loss: 0.0904\n",
      "Epoch [5730/10000], Loss: 0.0904\n",
      "Epoch [5740/10000], Loss: 0.0904\n",
      "Epoch [5750/10000], Loss: 0.0904\n",
      "Epoch [5760/10000], Loss: 0.0904\n",
      "Epoch [5770/10000], Loss: 0.0904\n",
      "Epoch [5780/10000], Loss: 0.0904\n",
      "Epoch [5790/10000], Loss: 0.0904\n",
      "Epoch [5800/10000], Loss: 0.0904\n",
      "Epoch [5810/10000], Loss: 0.0904\n",
      "Epoch [5820/10000], Loss: 0.0904\n",
      "Epoch [5830/10000], Loss: 0.0904\n",
      "Epoch [5840/10000], Loss: 0.0904\n",
      "Epoch [5850/10000], Loss: 0.0904\n",
      "Epoch [5860/10000], Loss: 0.0904\n",
      "Epoch [5870/10000], Loss: 0.0904\n",
      "Epoch [5880/10000], Loss: 0.0904\n",
      "Epoch [5890/10000], Loss: 0.0904\n",
      "Epoch [5900/10000], Loss: 0.0904\n",
      "Epoch [5910/10000], Loss: 0.0904\n",
      "Epoch [5920/10000], Loss: 0.0904\n",
      "Epoch [5930/10000], Loss: 0.0904\n",
      "Epoch [5940/10000], Loss: 0.0904\n",
      "Epoch [5950/10000], Loss: 0.0904\n",
      "Epoch [5960/10000], Loss: 0.0904\n",
      "Epoch [5970/10000], Loss: 0.0904\n",
      "Epoch [5980/10000], Loss: 0.0904\n",
      "Epoch [5990/10000], Loss: 0.0904\n",
      "Epoch [6000/10000], Loss: 0.0904\n",
      "Epoch [6010/10000], Loss: 0.0904\n",
      "Epoch [6020/10000], Loss: 0.0904\n",
      "Epoch [6030/10000], Loss: 0.0904\n",
      "Epoch [6040/10000], Loss: 0.0904\n",
      "Epoch [6050/10000], Loss: 0.0904\n",
      "Epoch [6060/10000], Loss: 0.0904\n",
      "Epoch [6070/10000], Loss: 0.0904\n",
      "Epoch [6080/10000], Loss: 0.0904\n",
      "Epoch [6090/10000], Loss: 0.0904\n",
      "Epoch [6100/10000], Loss: 0.0904\n",
      "Epoch [6110/10000], Loss: 0.0904\n",
      "Epoch [6120/10000], Loss: 0.0904\n",
      "Epoch [6130/10000], Loss: 0.0904\n",
      "Epoch [6140/10000], Loss: 0.0904\n",
      "Epoch [6150/10000], Loss: 0.0904\n",
      "Epoch [6160/10000], Loss: 0.0904\n",
      "Epoch [6170/10000], Loss: 0.0904\n",
      "Epoch [6180/10000], Loss: 0.0904\n",
      "Epoch [6190/10000], Loss: 0.0904\n",
      "Epoch [6200/10000], Loss: 0.0904\n",
      "Epoch [6210/10000], Loss: 0.0904\n",
      "Epoch [6220/10000], Loss: 0.0904\n",
      "Epoch [6230/10000], Loss: 0.0904\n",
      "Epoch [6240/10000], Loss: 0.0904\n",
      "Epoch [6250/10000], Loss: 0.0904\n",
      "Epoch [6260/10000], Loss: 0.0904\n",
      "Epoch [6270/10000], Loss: 0.0904\n",
      "Epoch [6280/10000], Loss: 0.0904\n",
      "Epoch [6290/10000], Loss: 0.0904\n",
      "Epoch [6300/10000], Loss: 0.0904\n",
      "Epoch [6310/10000], Loss: 0.0904\n",
      "Epoch [6320/10000], Loss: 0.0904\n",
      "Epoch [6330/10000], Loss: 0.0904\n",
      "Epoch [6340/10000], Loss: 0.0904\n",
      "Epoch [6350/10000], Loss: 0.0904\n",
      "Epoch [6360/10000], Loss: 0.0904\n",
      "Epoch [6370/10000], Loss: 0.0904\n",
      "Epoch [6380/10000], Loss: 0.0904\n",
      "Epoch [6390/10000], Loss: 0.0904\n",
      "Epoch [6400/10000], Loss: 0.0904\n",
      "Epoch [6410/10000], Loss: 0.0904\n",
      "Epoch [6420/10000], Loss: 0.0904\n",
      "Epoch [6430/10000], Loss: 0.0904\n",
      "Epoch [6440/10000], Loss: 0.0904\n",
      "Epoch [6450/10000], Loss: 0.0904\n",
      "Epoch [6460/10000], Loss: 0.0904\n",
      "Epoch [6470/10000], Loss: 0.0904\n",
      "Epoch [6480/10000], Loss: 0.0904\n",
      "Epoch [6490/10000], Loss: 0.0904\n",
      "Epoch [6500/10000], Loss: 0.0904\n",
      "Epoch [6510/10000], Loss: 0.0904\n",
      "Epoch [6520/10000], Loss: 0.0904\n",
      "Epoch [6530/10000], Loss: 0.0904\n",
      "Epoch [6540/10000], Loss: 0.0904\n",
      "Epoch [6550/10000], Loss: 0.0904\n",
      "Epoch [6560/10000], Loss: 0.0904\n",
      "Epoch [6570/10000], Loss: 0.0904\n",
      "Epoch [6580/10000], Loss: 0.0904\n",
      "Epoch [6590/10000], Loss: 0.0904\n",
      "Epoch [6600/10000], Loss: 0.0904\n",
      "Epoch [6610/10000], Loss: 0.0904\n",
      "Epoch [6620/10000], Loss: 0.0904\n",
      "Epoch [6630/10000], Loss: 0.0904\n",
      "Epoch [6640/10000], Loss: 0.0904\n",
      "Epoch [6650/10000], Loss: 0.0904\n",
      "Epoch [6660/10000], Loss: 0.0904\n",
      "Epoch [6670/10000], Loss: 0.0904\n",
      "Epoch [6680/10000], Loss: 0.0904\n",
      "Epoch [6690/10000], Loss: 0.0904\n",
      "Epoch [6700/10000], Loss: 0.0904\n",
      "Epoch [6710/10000], Loss: 0.0904\n",
      "Epoch [6720/10000], Loss: 0.0904\n",
      "Epoch [6730/10000], Loss: 0.0904\n",
      "Epoch [6740/10000], Loss: 0.0904\n",
      "Epoch [6750/10000], Loss: 0.0904\n",
      "Epoch [6760/10000], Loss: 0.0904\n",
      "Epoch [6770/10000], Loss: 0.0904\n",
      "Epoch [6780/10000], Loss: 0.0904\n",
      "Epoch [6790/10000], Loss: 0.0904\n",
      "Epoch [6800/10000], Loss: 0.0904\n",
      "Epoch [6810/10000], Loss: 0.0904\n",
      "Epoch [6820/10000], Loss: 0.0904\n",
      "Epoch [6830/10000], Loss: 0.0904\n",
      "Epoch [6840/10000], Loss: 0.0904\n",
      "Epoch [6850/10000], Loss: 0.0904\n",
      "Epoch [6860/10000], Loss: 0.0904\n",
      "Epoch [6870/10000], Loss: 0.0904\n",
      "Epoch [6880/10000], Loss: 0.0904\n",
      "Epoch [6890/10000], Loss: 0.0904\n",
      "Epoch [6900/10000], Loss: 0.0904\n",
      "Epoch [6910/10000], Loss: 0.0904\n",
      "Epoch [6920/10000], Loss: 0.0904\n",
      "Epoch [6930/10000], Loss: 0.0904\n",
      "Epoch [6940/10000], Loss: 0.0904\n",
      "Epoch [6950/10000], Loss: 0.0904\n",
      "Epoch [6960/10000], Loss: 0.0904\n",
      "Epoch [6970/10000], Loss: 0.0904\n",
      "Epoch [6980/10000], Loss: 0.0904\n",
      "Epoch [6990/10000], Loss: 0.0904\n",
      "Epoch [7000/10000], Loss: 0.0904\n",
      "Epoch [7010/10000], Loss: 0.0904\n",
      "Epoch [7020/10000], Loss: 0.0904\n",
      "Epoch [7030/10000], Loss: 0.0904\n",
      "Epoch [7040/10000], Loss: 0.0904\n",
      "Epoch [7050/10000], Loss: 0.0904\n",
      "Epoch [7060/10000], Loss: 0.0904\n",
      "Epoch [7070/10000], Loss: 0.0904\n",
      "Epoch [7080/10000], Loss: 0.0904\n",
      "Epoch [7090/10000], Loss: 0.0904\n",
      "Epoch [7100/10000], Loss: 0.0904\n",
      "Epoch [7110/10000], Loss: 0.0904\n",
      "Epoch [7120/10000], Loss: 0.0904\n",
      "Epoch [7130/10000], Loss: 0.0904\n",
      "Epoch [7140/10000], Loss: 0.0904\n",
      "Epoch [7150/10000], Loss: 0.0904\n",
      "Epoch [7160/10000], Loss: 0.0904\n",
      "Epoch [7170/10000], Loss: 0.0904\n",
      "Epoch [7180/10000], Loss: 0.0904\n",
      "Epoch [7190/10000], Loss: 0.0904\n",
      "Epoch [7200/10000], Loss: 0.0904\n",
      "Epoch [7210/10000], Loss: 0.0904\n",
      "Epoch [7220/10000], Loss: 0.0904\n",
      "Epoch [7230/10000], Loss: 0.0904\n",
      "Epoch [7240/10000], Loss: 0.0904\n",
      "Epoch [7250/10000], Loss: 0.0904\n",
      "Epoch [7260/10000], Loss: 0.0904\n",
      "Epoch [7270/10000], Loss: 0.0904\n",
      "Epoch [7280/10000], Loss: 0.0904\n",
      "Epoch [7290/10000], Loss: 0.0904\n",
      "Epoch [7300/10000], Loss: 0.0904\n",
      "Epoch [7310/10000], Loss: 0.0904\n",
      "Epoch [7320/10000], Loss: 0.0904\n",
      "Epoch [7330/10000], Loss: 0.0904\n",
      "Epoch [7340/10000], Loss: 0.0904\n",
      "Epoch [7350/10000], Loss: 0.0904\n",
      "Epoch [7360/10000], Loss: 0.0904\n",
      "Epoch [7370/10000], Loss: 0.0904\n",
      "Epoch [7380/10000], Loss: 0.0904\n",
      "Epoch [7390/10000], Loss: 0.0904\n",
      "Epoch [7400/10000], Loss: 0.0904\n",
      "Epoch [7410/10000], Loss: 0.0904\n",
      "Epoch [7420/10000], Loss: 0.0904\n",
      "Epoch [7430/10000], Loss: 0.0904\n",
      "Epoch [7440/10000], Loss: 0.0904\n",
      "Epoch [7450/10000], Loss: 0.0904\n",
      "Epoch [7460/10000], Loss: 0.0904\n",
      "Epoch [7470/10000], Loss: 0.0904\n",
      "Epoch [7480/10000], Loss: 0.0904\n",
      "Epoch [7490/10000], Loss: 0.0904\n",
      "Epoch [7500/10000], Loss: 0.0904\n",
      "Epoch [7510/10000], Loss: 0.0904\n",
      "Epoch [7520/10000], Loss: 0.0904\n",
      "Epoch [7530/10000], Loss: 0.0904\n",
      "Epoch [7540/10000], Loss: 0.0904\n",
      "Epoch [7550/10000], Loss: 0.0904\n",
      "Epoch [7560/10000], Loss: 0.0904\n",
      "Epoch [7570/10000], Loss: 0.0904\n",
      "Epoch [7580/10000], Loss: 0.0904\n",
      "Epoch [7590/10000], Loss: 0.0904\n",
      "Epoch [7600/10000], Loss: 0.0904\n",
      "Epoch [7610/10000], Loss: 0.0904\n",
      "Epoch [7620/10000], Loss: 0.0904\n",
      "Epoch [7630/10000], Loss: 0.0904\n",
      "Epoch [7640/10000], Loss: 0.0904\n",
      "Epoch [7650/10000], Loss: 0.0904\n",
      "Epoch [7660/10000], Loss: 0.0904\n",
      "Epoch [7670/10000], Loss: 0.0904\n",
      "Epoch [7680/10000], Loss: 0.0904\n",
      "Epoch [7690/10000], Loss: 0.0904\n",
      "Epoch [7700/10000], Loss: 0.0904\n",
      "Epoch [7710/10000], Loss: 0.0904\n",
      "Epoch [7720/10000], Loss: 0.0904\n",
      "Epoch [7730/10000], Loss: 0.0904\n",
      "Epoch [7740/10000], Loss: 0.0904\n",
      "Epoch [7750/10000], Loss: 0.0904\n",
      "Epoch [7760/10000], Loss: 0.0904\n",
      "Epoch [7770/10000], Loss: 0.0904\n",
      "Epoch [7780/10000], Loss: 0.0904\n",
      "Epoch [7790/10000], Loss: 0.0904\n",
      "Epoch [7800/10000], Loss: 0.0904\n",
      "Epoch [7810/10000], Loss: 0.0904\n",
      "Epoch [7820/10000], Loss: 0.0904\n",
      "Epoch [7830/10000], Loss: 0.0904\n",
      "Epoch [7840/10000], Loss: 0.0904\n",
      "Epoch [7850/10000], Loss: 0.0904\n",
      "Epoch [7860/10000], Loss: 0.0904\n",
      "Epoch [7870/10000], Loss: 0.0904\n",
      "Epoch [7880/10000], Loss: 0.0904\n",
      "Epoch [7890/10000], Loss: 0.0904\n",
      "Epoch [7900/10000], Loss: 0.0904\n",
      "Epoch [7910/10000], Loss: 0.0904\n",
      "Epoch [7920/10000], Loss: 0.0904\n",
      "Epoch [7930/10000], Loss: 0.0904\n",
      "Epoch [7940/10000], Loss: 0.0904\n",
      "Epoch [7950/10000], Loss: 0.0904\n",
      "Epoch [7960/10000], Loss: 0.0904\n",
      "Epoch [7970/10000], Loss: 0.0904\n",
      "Epoch [7980/10000], Loss: 0.0904\n",
      "Epoch [7990/10000], Loss: 0.0904\n",
      "Epoch [8000/10000], Loss: 0.0904\n",
      "Epoch [8010/10000], Loss: 0.0904\n",
      "Epoch [8020/10000], Loss: 0.0904\n",
      "Epoch [8030/10000], Loss: 0.0904\n",
      "Epoch [8040/10000], Loss: 0.0904\n",
      "Epoch [8050/10000], Loss: 0.0904\n",
      "Epoch [8060/10000], Loss: 0.0904\n",
      "Epoch [8070/10000], Loss: 0.0904\n",
      "Epoch [8080/10000], Loss: 0.0904\n",
      "Epoch [8090/10000], Loss: 0.0904\n",
      "Epoch [8100/10000], Loss: 0.0904\n",
      "Epoch [8110/10000], Loss: 0.0904\n",
      "Epoch [8120/10000], Loss: 0.0904\n",
      "Epoch [8130/10000], Loss: 0.0904\n",
      "Epoch [8140/10000], Loss: 0.0904\n",
      "Epoch [8150/10000], Loss: 0.0904\n",
      "Epoch [8160/10000], Loss: 0.0904\n",
      "Epoch [8170/10000], Loss: 0.0904\n",
      "Epoch [8180/10000], Loss: 0.0904\n",
      "Epoch [8190/10000], Loss: 0.0904\n",
      "Epoch [8200/10000], Loss: 0.0904\n",
      "Epoch [8210/10000], Loss: 0.0904\n",
      "Epoch [8220/10000], Loss: 0.0904\n",
      "Epoch [8230/10000], Loss: 0.0904\n",
      "Epoch [8240/10000], Loss: 0.0904\n",
      "Epoch [8250/10000], Loss: 0.0904\n",
      "Epoch [8260/10000], Loss: 0.0904\n",
      "Epoch [8270/10000], Loss: 0.0904\n",
      "Epoch [8280/10000], Loss: 0.0904\n",
      "Epoch [8290/10000], Loss: 0.0904\n",
      "Epoch [8300/10000], Loss: 0.0904\n",
      "Epoch [8310/10000], Loss: 0.0904\n",
      "Epoch [8320/10000], Loss: 0.0904\n",
      "Epoch [8330/10000], Loss: 0.0904\n",
      "Epoch [8340/10000], Loss: 0.0904\n",
      "Epoch [8350/10000], Loss: 0.0904\n",
      "Epoch [8360/10000], Loss: 0.0904\n",
      "Epoch [8370/10000], Loss: 0.0904\n",
      "Epoch [8380/10000], Loss: 0.0904\n",
      "Epoch [8390/10000], Loss: 0.0904\n",
      "Epoch [8400/10000], Loss: 0.0904\n",
      "Epoch [8410/10000], Loss: 0.0904\n",
      "Epoch [8420/10000], Loss: 0.0904\n",
      "Epoch [8430/10000], Loss: 0.0904\n",
      "Epoch [8440/10000], Loss: 0.0904\n",
      "Epoch [8450/10000], Loss: 0.0904\n",
      "Epoch [8460/10000], Loss: 0.0904\n",
      "Epoch [8470/10000], Loss: 0.0904\n",
      "Epoch [8480/10000], Loss: 0.0904\n",
      "Epoch [8490/10000], Loss: 0.0904\n",
      "Epoch [8500/10000], Loss: 0.0904\n",
      "Epoch [8510/10000], Loss: 0.0904\n",
      "Epoch [8520/10000], Loss: 0.0904\n",
      "Epoch [8530/10000], Loss: 0.0904\n",
      "Epoch [8540/10000], Loss: 0.0904\n",
      "Epoch [8550/10000], Loss: 0.0904\n",
      "Epoch [8560/10000], Loss: 0.0904\n",
      "Epoch [8570/10000], Loss: 0.0904\n",
      "Epoch [8580/10000], Loss: 0.0904\n",
      "Epoch [8590/10000], Loss: 0.0904\n",
      "Epoch [8600/10000], Loss: 0.0904\n",
      "Epoch [8610/10000], Loss: 0.0904\n",
      "Epoch [8620/10000], Loss: 0.0904\n",
      "Epoch [8630/10000], Loss: 0.0904\n",
      "Epoch [8640/10000], Loss: 0.0904\n",
      "Epoch [8650/10000], Loss: 0.0904\n",
      "Epoch [8660/10000], Loss: 0.0904\n",
      "Epoch [8670/10000], Loss: 0.0904\n",
      "Epoch [8680/10000], Loss: 0.0904\n",
      "Epoch [8690/10000], Loss: 0.0904\n",
      "Epoch [8700/10000], Loss: 0.0904\n",
      "Epoch [8710/10000], Loss: 0.0904\n",
      "Epoch [8720/10000], Loss: 0.0904\n",
      "Epoch [8730/10000], Loss: 0.0904\n",
      "Epoch [8740/10000], Loss: 0.0904\n",
      "Epoch [8750/10000], Loss: 0.0904\n",
      "Epoch [8760/10000], Loss: 0.0904\n",
      "Epoch [8770/10000], Loss: 0.0904\n",
      "Epoch [8780/10000], Loss: 0.0904\n",
      "Epoch [8790/10000], Loss: 0.0904\n",
      "Epoch [8800/10000], Loss: 0.0904\n",
      "Epoch [8810/10000], Loss: 0.0904\n",
      "Epoch [8820/10000], Loss: 0.0904\n",
      "Epoch [8830/10000], Loss: 0.0904\n",
      "Epoch [8840/10000], Loss: 0.0904\n",
      "Epoch [8850/10000], Loss: 0.0904\n",
      "Epoch [8860/10000], Loss: 0.0904\n",
      "Epoch [8870/10000], Loss: 0.0904\n",
      "Epoch [8880/10000], Loss: 0.0904\n",
      "Epoch [8890/10000], Loss: 0.0904\n",
      "Epoch [8900/10000], Loss: 0.0904\n",
      "Epoch [8910/10000], Loss: 0.0904\n",
      "Epoch [8920/10000], Loss: 0.0904\n",
      "Epoch [8930/10000], Loss: 0.0904\n",
      "Epoch [8940/10000], Loss: 0.0904\n",
      "Epoch [8950/10000], Loss: 0.0904\n",
      "Epoch [8960/10000], Loss: 0.0904\n",
      "Epoch [8970/10000], Loss: 0.0904\n",
      "Epoch [8980/10000], Loss: 0.0904\n",
      "Epoch [8990/10000], Loss: 0.0904\n",
      "Epoch [9000/10000], Loss: 0.0904\n",
      "Epoch [9010/10000], Loss: 0.0904\n",
      "Epoch [9020/10000], Loss: 0.0904\n",
      "Epoch [9030/10000], Loss: 0.0904\n",
      "Epoch [9040/10000], Loss: 0.0904\n",
      "Epoch [9050/10000], Loss: 0.0904\n",
      "Epoch [9060/10000], Loss: 0.0904\n",
      "Epoch [9070/10000], Loss: 0.0904\n",
      "Epoch [9080/10000], Loss: 0.0904\n",
      "Epoch [9090/10000], Loss: 0.0904\n",
      "Epoch [9100/10000], Loss: 0.0904\n",
      "Epoch [9110/10000], Loss: 0.0904\n",
      "Epoch [9120/10000], Loss: 0.0904\n",
      "Epoch [9130/10000], Loss: 0.0904\n",
      "Epoch [9140/10000], Loss: 0.0904\n",
      "Epoch [9150/10000], Loss: 0.0904\n",
      "Epoch [9160/10000], Loss: 0.0904\n",
      "Epoch [9170/10000], Loss: 0.0904\n",
      "Epoch [9180/10000], Loss: 0.0904\n",
      "Epoch [9190/10000], Loss: 0.0904\n",
      "Epoch [9200/10000], Loss: 0.0904\n",
      "Epoch [9210/10000], Loss: 0.0904\n",
      "Epoch [9220/10000], Loss: 0.0904\n",
      "Epoch [9230/10000], Loss: 0.0904\n",
      "Epoch [9240/10000], Loss: 0.0904\n",
      "Epoch [9250/10000], Loss: 0.0904\n",
      "Epoch [9260/10000], Loss: 0.0904\n",
      "Epoch [9270/10000], Loss: 0.0904\n",
      "Epoch [9280/10000], Loss: 0.0904\n",
      "Epoch [9290/10000], Loss: 0.0904\n",
      "Epoch [9300/10000], Loss: 0.0904\n",
      "Epoch [9310/10000], Loss: 0.0904\n",
      "Epoch [9320/10000], Loss: 0.0904\n",
      "Epoch [9330/10000], Loss: 0.0904\n",
      "Epoch [9340/10000], Loss: 0.0904\n",
      "Epoch [9350/10000], Loss: 0.0904\n",
      "Epoch [9360/10000], Loss: 0.0904\n",
      "Epoch [9370/10000], Loss: 0.0904\n",
      "Epoch [9380/10000], Loss: 0.0904\n",
      "Epoch [9390/10000], Loss: 0.0904\n",
      "Epoch [9400/10000], Loss: 0.0904\n",
      "Epoch [9410/10000], Loss: 0.0904\n",
      "Epoch [9420/10000], Loss: 0.0904\n",
      "Epoch [9430/10000], Loss: 0.0904\n",
      "Epoch [9440/10000], Loss: 0.0904\n",
      "Epoch [9450/10000], Loss: 0.0904\n",
      "Epoch [9460/10000], Loss: 0.0904\n",
      "Epoch [9470/10000], Loss: 0.0904\n",
      "Epoch [9480/10000], Loss: 0.0904\n",
      "Epoch [9490/10000], Loss: 0.0904\n",
      "Epoch [9500/10000], Loss: 0.0904\n",
      "Epoch [9510/10000], Loss: 0.0904\n",
      "Epoch [9520/10000], Loss: 0.0904\n",
      "Epoch [9530/10000], Loss: 0.0904\n",
      "Epoch [9540/10000], Loss: 0.0904\n",
      "Epoch [9550/10000], Loss: 0.0904\n",
      "Epoch [9560/10000], Loss: 0.0904\n",
      "Epoch [9570/10000], Loss: 0.0904\n",
      "Epoch [9580/10000], Loss: 0.0904\n",
      "Epoch [9590/10000], Loss: 0.0904\n",
      "Epoch [9600/10000], Loss: 0.0904\n",
      "Epoch [9610/10000], Loss: 0.0904\n",
      "Epoch [9620/10000], Loss: 0.0904\n",
      "Epoch [9630/10000], Loss: 0.0904\n",
      "Epoch [9640/10000], Loss: 0.0904\n",
      "Epoch [9650/10000], Loss: 0.0904\n",
      "Epoch [9660/10000], Loss: 0.0904\n",
      "Epoch [9670/10000], Loss: 0.0904\n",
      "Epoch [9680/10000], Loss: 0.0904\n",
      "Epoch [9690/10000], Loss: 0.0904\n",
      "Epoch [9700/10000], Loss: 0.0904\n",
      "Epoch [9710/10000], Loss: 0.0904\n",
      "Epoch [9720/10000], Loss: 0.0904\n",
      "Epoch [9730/10000], Loss: 0.0904\n",
      "Epoch [9740/10000], Loss: 0.0904\n",
      "Epoch [9750/10000], Loss: 0.0904\n",
      "Epoch [9760/10000], Loss: 0.0904\n",
      "Epoch [9770/10000], Loss: 0.0904\n",
      "Epoch [9780/10000], Loss: 0.0904\n",
      "Epoch [9790/10000], Loss: 0.0904\n",
      "Epoch [9800/10000], Loss: 0.0904\n",
      "Epoch [9810/10000], Loss: 0.0904\n",
      "Epoch [9820/10000], Loss: 0.0904\n",
      "Epoch [9830/10000], Loss: 0.0904\n",
      "Epoch [9840/10000], Loss: 0.0904\n",
      "Epoch [9850/10000], Loss: 0.0904\n",
      "Epoch [9860/10000], Loss: 0.0904\n",
      "Epoch [9870/10000], Loss: 0.0904\n",
      "Epoch [9880/10000], Loss: 0.0904\n",
      "Epoch [9890/10000], Loss: 0.0904\n",
      "Epoch [9900/10000], Loss: 0.0904\n",
      "Epoch [9910/10000], Loss: 0.0904\n",
      "Epoch [9920/10000], Loss: 0.0904\n",
      "Epoch [9930/10000], Loss: 0.0904\n",
      "Epoch [9940/10000], Loss: 0.0904\n",
      "Epoch [9950/10000], Loss: 0.0904\n",
      "Epoch [9960/10000], Loss: 0.0904\n",
      "Epoch [9970/10000], Loss: 0.0904\n",
      "Epoch [9980/10000], Loss: 0.0904\n",
      "Epoch [9990/10000], Loss: 0.0904\n",
      "Epoch [10000/10000], Loss: 0.0904\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05, weight_decay=0.05)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "\n",
    "    # Backward pass và tối ưu hóa\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=0.01, coef0=1, degree=3, gamma=None, kernel='linear',\n",
       "            kernel_params=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KernelRidge(alpha=0.01)\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCL2Layer(nn.Module):\n",
    "    def __init__(self, n_feature, num_class):\n",
    "        super(FCL2Layer, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_feature, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.output = nn.Linear(128, num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "def predict(model, X):\n",
    "    model.eval()  # Chuyển sang chế độ eval để tắt dropout/batchnorm nếu có\n",
    "    with torch.no_grad():  # Tắt gradient để giảm bớt bộ nhớ\n",
    "        outputs = model(X)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression(penalty='l1', C=0.1, solver='saga', multi_class='multi_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 1, ..., 5, 1, 7])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.where(Y_matrix == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 1, ..., 5, 1, 7])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 1, ..., 5, 1, 7])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 159660 into shape (4435,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ffa7af881c97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKernelReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/statsmodels/nonparametric/kernel_regression.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, var_type, reg_type, bw, defaults)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_adjust_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_adjust_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/statsmodels/nonparametric/_kernel_base.py\u001b[0m in \u001b[0;36m_adjust_shape\u001b[0;34m(dat, k_vars)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# ndim >1 so many obs many vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    299\u001b[0m            [5, 6]])\n\u001b[1;32m    300\u001b[0m     \"\"\"\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 159660 into shape (4435,1)"
     ]
    }
   ],
   "source": [
    "model = KernelReg([1,100,1], X, var_type='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'333'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'3'*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cccccccccccccccccccccccccccccccccccc'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'c'*X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_u = sm.nonparametric.KDEMultivariate(data=X, var_type='c'*dim, bw='normal_reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.56532044)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dens_u.pdf(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = dens_u.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y[:50]\n",
    "X = X[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_u = sm.nonparametric.KDEMultivariate(data=X, var_type='c'*X.shape[1], bw='normal_reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KernelReg(Y, X, var_type='c'*X.shape[1], reg_type='lc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19174831, 0.28450028, 0.27009914, 0.15901443, 0.30847048,\n",
       "       0.28977343, 0.17193598, 0.03891559, 0.20149673, 0.31748389,\n",
       "       0.28018324, 0.28895554, 0.15374873, 0.21203015, 0.57902868,\n",
       "       0.05410153])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, x = model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 16)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119904"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.73930242, 4.83120944, 4.76830902, 4.05162109, 4.54722321,\n",
       "        4.90765989, 4.45411434, 4.89109568, 4.71458883, 4.78442258,\n",
       "        4.7987667 , 4.75148552, 4.46570638, 4.97899378, 4.98634629,\n",
       "        4.81090934]),\n",
       " array([[-2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15,\n",
       "         -2.42074379e+15, -2.42074379e+15, -2.42074379e+15],\n",
       "        [-1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16,\n",
       "         -1.80097159e+16, -1.80097159e+16, -1.80097159e+16],\n",
       "        [-1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16,\n",
       "         -1.01969841e+16, -1.01969841e+16, -1.01969841e+16],\n",
       "        [-1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16,\n",
       "         -1.85016927e+16, -1.85016927e+16, -1.85016927e+16],\n",
       "        [-1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16,\n",
       "         -1.08467117e+16, -1.08467117e+16, -1.08467117e+16],\n",
       "        [-1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16,\n",
       "         -1.14534011e+16, -1.14534011e+16, -1.14534011e+16],\n",
       "        [-4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15,\n",
       "         -4.58262557e+15, -4.58262557e+15, -4.58262557e+15],\n",
       "        [-6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15,\n",
       "         -6.84514435e+15, -6.84514435e+15, -6.84514435e+15],\n",
       "        [ 1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16,\n",
       "          1.56924872e+16,  1.56924872e+16,  1.56924872e+16],\n",
       "        [-9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14,\n",
       "         -9.31466971e+14, -9.31466971e+14, -9.31466971e+14],\n",
       "        [-2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16,\n",
       "         -2.11527895e+16, -2.11527895e+16, -2.11527895e+16],\n",
       "        [-1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16,\n",
       "         -1.96603423e+16, -1.96603423e+16, -1.96603423e+16],\n",
       "        [-2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16,\n",
       "         -2.28852801e+16, -2.28852801e+16, -2.28852801e+16],\n",
       "        [-2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15,\n",
       "         -2.31623367e+15, -2.31623367e+15, -2.31623367e+15],\n",
       "        [-4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15,\n",
       "         -4.30702131e+15, -4.30702131e+15, -4.30702131e+15],\n",
       "        [-1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15,\n",
       "         -1.51003302e+15, -1.51003302e+15, -1.51003302e+15]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X[-16:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4435, 36)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.]), array([[-99.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2857443  0.1952922  0.26814298 0.07805563 0.05606263 0.11670226]\n",
      " [0.29536795 0.15428734 0.27987302 0.0802635  0.05640643 0.13380176]\n",
      " [0.37533892 0.1459109  0.18370155 0.12563121 0.06332002 0.10609741]\n",
      " ...\n",
      " [0.20679231 0.16011928 0.29419599 0.0838981  0.1119685  0.14302582]\n",
      " [0.31595816 0.13683452 0.25687274 0.10179922 0.11506038 0.07347497]\n",
      " [0.28837575 0.1668954  0.27622361 0.06731022 0.08418668 0.11700835]]\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08136092229213432, tolerance: 0.04414618372652263\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08136092229213432, tolerance: 0.04414618372652263\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09048368117350947, tolerance: 0.04430395631018423\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09048368117350947, tolerance: 0.04430395631018423\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08161668621410456, tolerance: 0.04447331896825037\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08161668621410456, tolerance: 0.04447331896825037\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00056\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00006\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 31.56571\n",
      "sigma = 1.00000, lambda = 0.01000, score = -1.17952\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.35085\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.38121\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.45369\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.06027\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00623\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00062\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 2105.09781\n",
      "sigma = 10.00000, lambda = 0.01000, score = 410.15885\n",
      "sigma = 10.00000, lambda = 0.10000, score = 10.66124\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.53089\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52516\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37793\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08145\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00911\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 20.09672\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.46082\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50031\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50023\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49609\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37495\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08672\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49995\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.47\n",
      "Approximate alpha-relative KL-divergence = 1.38\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00073\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00007\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 33.96512\n",
      "sigma = 1.00000, lambda = 0.01000, score = -1.36617\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.53581\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.51109\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.47588\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.06146\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00633\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00063\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1656.12344\n",
      "sigma = 10.00000, lambda = 0.01000, score = 390.18081\n",
      "sigma = 10.00000, lambda = 0.10000, score = 10.43140\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52032\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52560\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37866\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08175\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00914\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00093\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 18.40631\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.45219\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50032\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50023\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49609\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37495\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08672\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49995\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.46\n",
      "Approximate alpha-relative KL-divergence = 1.39\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03031991178854554, tolerance: 0.02230264291344382\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03031991178854554, tolerance: 0.02230264291344382\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.043619514194688236, tolerance: 0.022751581831235764\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.043619514194688236, tolerance: 0.022751581831235764\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00072\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00007\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 28.91635\n",
      "sigma = 1.00000, lambda = 0.01000, score = -0.78712\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.22179\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.30595\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.42709\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05663\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00585\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00059\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1701.65429\n",
      "sigma = 10.00000, lambda = 0.01000, score = 430.16227\n",
      "sigma = 10.00000, lambda = 0.10000, score = 14.54468\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.50482\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52391\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37739\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08152\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00912\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 28.82476\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.42002\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50030\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50020\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49601\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37485\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08676\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -0.95\n",
      "Approximate alpha-relative KL-divergence = 1.31\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0439595261181438, tolerance: 0.02206473411299383\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0439595261181438, tolerance: 0.02206473411299383\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03466387270604798, tolerance: 0.022250593846881925\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03466387270604798, tolerance: 0.022250593846881925\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04257241943840029, tolerance: 0.02164541446099271\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04257241943840029, tolerance: 0.02164541446099271\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02999003355433416, tolerance: 0.021463531141462978\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02999003355433416, tolerance: 0.021463531141462978\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.029693701291321872, tolerance: 0.02147754261963311\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.029693701291321872, tolerance: 0.02147754261963311\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00108\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00011\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 59.50772\n",
      "sigma = 1.00000, lambda = 0.01000, score = -2.21544\n",
      "sigma = 1.00000, lambda = 0.10000, score = -3.19060\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.54425\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.43621\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05483\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00563\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00056\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1845.37172\n",
      "sigma = 10.00000, lambda = 0.01000, score = 362.72388\n",
      "sigma = 10.00000, lambda = 0.10000, score = 12.63708\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.50617\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52621\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37752\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08130\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00909\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 23.92714\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.42282\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50033\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50023\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49603\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37485\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08676\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -0.86\n",
      "Approximate alpha-relative KL-divergence = 1.42\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00102\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00010\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 48.74342\n",
      "sigma = 1.00000, lambda = 0.01000, score = 1.12235\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.43478\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.49822\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.47382\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.06167\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00636\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00064\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1999.37845\n",
      "sigma = 10.00000, lambda = 0.01000, score = 430.62733\n",
      "sigma = 10.00000, lambda = 0.10000, score = 12.26423\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52086\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52619\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37945\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08199\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00917\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00093\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 21.90755\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.44597\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50032\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50023\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49604\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37487\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08672\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.33\n",
      "Approximate alpha-relative KL-divergence = 1.38\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00078\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00008\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 46.87919\n",
      "sigma = 1.00000, lambda = 0.01000, score = -2.06557\n",
      "sigma = 1.00000, lambda = 0.10000, score = -3.14872\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.50040\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.42257\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05335\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00548\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00055\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00005\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 2182.46624\n",
      "sigma = 10.00000, lambda = 0.01000, score = 422.24404\n",
      "sigma = 10.00000, lambda = 0.10000, score = 11.09138\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52940\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52442\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37777\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08164\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00913\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 20.36423\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.45932\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50031\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50022\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49602\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37485\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -0.61\n",
      "Approximate alpha-relative KL-divergence = 1.36\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00149\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00015\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 62.54142\n",
      "sigma = 1.00000, lambda = 0.01000, score = 1.22332\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.16187\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.36914\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.47048\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.06229\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00643\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00065\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 10.00000, lambda = 0.00100, score = 1963.16851\n",
      "sigma = 10.00000, lambda = 0.01000, score = 365.56594\n",
      "sigma = 10.00000, lambda = 0.10000, score = 8.20643\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52881\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52418\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37816\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08173\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00914\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00093\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 14.14147\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.47064\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50030\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50022\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49602\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37485\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.28\n",
      "Approximate alpha-relative KL-divergence = 1.29\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.039658722675653735, tolerance: 0.022165703298471957\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.039658722675653735, tolerance: 0.022165703298471957\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.054870372145039426, tolerance: 0.02237794960418357\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.054870372145039426, tolerance: 0.02237794960418357\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03902818322756474, tolerance: 0.022544226827337432\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03902818322756474, tolerance: 0.022544226827337432\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.045200808209827414, tolerance: 0.022670570996965463\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.045200808209827414, tolerance: 0.022670570996965463\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00171\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00017\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00002\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 38.73322\n",
      "sigma = 1.00000, lambda = 0.01000, score = 0.12444\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.39572\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.43401\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.45452\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05947\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00613\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00062\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1964.32896\n",
      "sigma = 10.00000, lambda = 0.01000, score = 405.38895\n",
      "sigma = 10.00000, lambda = 0.10000, score = 9.64578\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52058\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52197\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37624\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08127\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00909\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 16.28299\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.46219\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50028\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50019\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49600\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37483\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08676\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.78\n",
      "Approximate alpha-relative KL-divergence = 1.32\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00112\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00011\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 53.07018\n",
      "sigma = 1.00000, lambda = 0.01000, score = -1.44841\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.55276\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.38294\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.42864\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05575\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00575\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00058\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1509.89988\n",
      "sigma = 10.00000, lambda = 0.01000, score = 398.00889\n",
      "sigma = 10.00000, lambda = 0.10000, score = 12.57141\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.51076\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52433\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37657\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08112\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00907\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 23.10916\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.43039\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50031\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50021\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49602\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37484\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08676\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.00\n",
      "Approximate alpha-relative KL-divergence = 1.30\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00116\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00012\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 50.76982\n",
      "sigma = 1.00000, lambda = 0.01000, score = -0.50875\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.48143\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.45807\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.43598\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05504\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00565\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00057\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00006\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1788.29679\n",
      "sigma = 10.00000, lambda = 0.01000, score = 340.14796\n",
      "sigma = 10.00000, lambda = 0.10000, score = 11.03595\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.51514\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52476\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37761\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08142\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00910\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 20.66439\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.44420\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50031\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50021\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49602\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37485\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49576\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49575\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37481\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -1.28\n",
      "Approximate alpha-relative KL-divergence = 1.42\n",
      "RuLSIF completed.\n",
      "0.0020615203965287134\n",
      "0.13496492396029341\n",
      "0.14052462440146124\n",
      "0.14454640025621163\n",
      "0.07316521953909505\n",
      "0.06772742895011623\n",
      "[[0.24102912 0.06764163 0.17187361 0.10285628 0.10133621 0.31526315]\n",
      " [0.22805161 0.16242707 0.24136784 0.13808953 0.09609416 0.1339698 ]\n",
      " [0.4419999  0.12967623 0.16618194 0.09248787 0.09328026 0.07637381]\n",
      " ...\n",
      " [0.22448224 0.16734621 0.23944092 0.13555183 0.10691164 0.12626715]\n",
      " [0.19431824 0.25503681 0.19142227 0.14680791 0.12565408 0.08676068]\n",
      " [0.22133478 0.12516184 0.21841313 0.15798502 0.12293443 0.15417081]]\n",
      "sigma:  0.001\n",
      "lda:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07433223137628175, tolerance: 0.040998332075193954\n",
      "  positive)\n",
      "/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07433223137628175, tolerance: 0.040998332075193954\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00051\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00005\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00001\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 23.52820\n",
      "sigma = 1.00000, lambda = 0.01000, score = -1.91904\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.53857\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.35261\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.39886\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.05087\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00523\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00052\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00005\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1886.07764\n",
      "sigma = 10.00000, lambda = 0.01000, score = 402.87575\n",
      "sigma = 10.00000, lambda = 0.10000, score = 10.98566\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52797\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52472\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37652\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08091\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00904\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00091\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 20.85918\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.45462\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50031\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50023\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49608\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37493\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49995\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 10000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 10000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 100000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 100000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 10000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 10000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 10000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 10000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 10000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 10000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 10000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 10000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10000000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 100000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 100000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 100000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 100000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 100000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 100000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 100000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000000000.00000, lambda = 1.00000, score = -0.49994\n",
      "sigma = 1000000000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000000000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000000000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000000000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000000000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000000000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000000000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000000000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000000000.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "Found optimal sigma = 1.000, lambda = 0.100.\n",
      "Optimizing theta...\n",
      "Approximate alpha-relative PE-divergence = -0.99\n",
      "Approximate alpha-relative KL-divergence = 1.29\n",
      "RuLSIF completed.\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "sigma:  0.001\n",
      "lda:  0.01\n",
      "RuLSIF starting...\n",
      "Searching for the optimal sigma and lambda...\n",
      "sigma = 0.00100, lambda = 0.00100, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.01000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 0.10000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 1000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 10000000.00000, score = 0.00000\n",
      "sigma = 0.00100, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.00100, lambda = 1000000000.00000, score = 0.00000\n",
      "sigma = 0.01000, lambda = 0.00100, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.01000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.01000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 0.00100, score = -0.00042\n",
      "sigma = 0.10000, lambda = 0.01000, score = -0.00004\n",
      "sigma = 0.10000, lambda = 0.10000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 0.10000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 0.00100, score = 28.70297\n",
      "sigma = 1.00000, lambda = 0.01000, score = -1.56904\n",
      "sigma = 1.00000, lambda = 0.10000, score = -2.85820\n",
      "sigma = 1.00000, lambda = 1.00000, score = -1.51123\n",
      "sigma = 1.00000, lambda = 10.00000, score = -0.40226\n",
      "sigma = 1.00000, lambda = 100.00000, score = -0.04921\n",
      "sigma = 1.00000, lambda = 1000.00000, score = -0.00503\n",
      "sigma = 1.00000, lambda = 10000.00000, score = -0.00050\n",
      "sigma = 1.00000, lambda = 100000.00000, score = -0.00005\n",
      "sigma = 1.00000, lambda = 1000000.00000, score = -0.00001\n",
      "sigma = 1.00000, lambda = 10000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 0.00100, score = 1973.13400\n",
      "sigma = 10.00000, lambda = 0.01000, score = 458.17791\n",
      "sigma = 10.00000, lambda = 0.10000, score = 13.48332\n",
      "sigma = 10.00000, lambda = 1.00000, score = -0.52377\n",
      "sigma = 10.00000, lambda = 10.00000, score = -0.52774\n",
      "sigma = 10.00000, lambda = 100.00000, score = -0.37798\n",
      "sigma = 10.00000, lambda = 1000.00000, score = -0.08104\n",
      "sigma = 10.00000, lambda = 10000.00000, score = -0.00905\n",
      "sigma = 10.00000, lambda = 100000.00000, score = -0.00092\n",
      "sigma = 10.00000, lambda = 1000000.00000, score = -0.00009\n",
      "sigma = 10.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 10.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 10.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 0.00100, score = 24.85998\n",
      "sigma = 100.00000, lambda = 0.01000, score = -0.43675\n",
      "sigma = 100.00000, lambda = 0.10000, score = -0.50034\n",
      "sigma = 100.00000, lambda = 1.00000, score = -0.50026\n",
      "sigma = 100.00000, lambda = 10.00000, score = -0.49611\n",
      "sigma = 100.00000, lambda = 100.00000, score = -0.37495\n",
      "sigma = 100.00000, lambda = 1000.00000, score = -0.08671\n",
      "sigma = 100.00000, lambda = 10000.00000, score = -0.00984\n",
      "sigma = 100.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 100.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 100.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 100.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 100.00000, lambda = 1000000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 0.00100, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.01000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 0.10000, score = -0.50000\n",
      "sigma = 1000.00000, lambda = 1.00000, score = -0.49995\n",
      "sigma = 1000.00000, lambda = 10.00000, score = -0.49581\n",
      "sigma = 1000.00000, lambda = 100.00000, score = -0.37491\n",
      "sigma = 1000.00000, lambda = 1000.00000, score = -0.08677\n",
      "sigma = 1000.00000, lambda = 10000.00000, score = -0.00985\n",
      "sigma = 1000.00000, lambda = 100000.00000, score = -0.00100\n",
      "sigma = 1000.00000, lambda = 1000000.00000, score = -0.00010\n",
      "sigma = 1000.00000, lambda = 10000000.00000, score = -0.00001\n",
      "sigma = 1000.00000, lambda = 100000000.00000, score = -0.00000\n",
      "sigma = 1000.00000, lambda = 1000000000.00000, score = -0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-afe327fa7d7e>\", line 45, in <module>\n",
      "    res_dr2 = dr(Y_historical_matrix, A_historical_matrix, X_seq_train, X_test, pi_evaluation_seq_train, pi_evaluation_test, classes, pi_behavior=pi_behavior_seq_train, method='Ridge')\n",
      "  File \"../cs_ope_estimator.py\", line 79, in dr\n",
      "    densratio_obj = densratio(X_evl, X_hst)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/core.py\", line 66, in densratio\n",
      "    result = RuLSIF(x, y, alpha, sigma_range, lambda_range, kernel_num, verbose)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/RuLSIF.py\", line 61, in RuLSIF\n",
      "    opt_params = search_sigma_and_lambda(x, y, alpha, centers, sigma_range, lambda_range, verbose)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/RuLSIF.py\", line 152, in search_sigma_and_lambda\n",
      "    phi_y = compute_kernel_Gaussian(y, centers, sigma)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/RuLSIF.py\", line 187, in compute_kernel_Gaussian\n",
      "    result = [[kernel_Gaussian(x, y, sigma) for y in y_list] for x in x_list]\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/RuLSIF.py\", line 187, in <listcomp>\n",
      "    result = [[kernel_Gaussian(x, y, sigma) for y in y_list] for x in x_list]\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/RuLSIF.py\", line 187, in <listcomp>\n",
      "    result = [[kernel_Gaussian(x, y, sigma) for y in y_list] for x in x_list]\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/densratio/RuLSIF.py\", line 194, in kernel_Gaussian\n",
      "    return exp(- (norm(x - y) ** 2) / (2 * sigma * sigma))\n",
      "  File \"<__array_function__ internals>\", line 6, in norm\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\", line 2483, in norm\n",
      "    ret = sqrt(sqnorm)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/posixpath.py\", line 385, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/Users/mkato/opt/anaconda3/lib/python3.7/posixpath.py\", line 366, in normpath\n",
      "    new_comps.append(comp)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "num_trials = 100\n",
    "alphas = [0.7, 0.4, 0.0]\n",
    "\n",
    "tau_list = np.zeros(num_trials)\n",
    "res_ipw3_list = np.zeros((num_trials, len(alphas)))\n",
    "res_dm_list = np.zeros((num_trials, len(alphas)))\n",
    "res_dml1_truew_list = np.zeros((num_trials, len(alphas)))\n",
    "res_dml2_truew_list = np.zeros((num_trials, len(alphas)))\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    X, Y, Y_matrix, train_test_split, x_prob, classes, N, N_train, N_test = data_generation(data_name)\n",
    "\n",
    "    X_train, X_test = X[train_test_split], X[~train_test_split]\n",
    "    Y_train, Y_test = Y[train_test_split], Y[~train_test_split]\n",
    "    Y_matrix_train, Y_matrix_test = Y_matrix[train_test_split], Y_matrix[~train_test_split]\n",
    "\n",
    "    pi_behavior, pi_evaluation  = behavior_and_evaluation_policy(X, Y, train_test_split, classes, alpha=0.7)\n",
    "\n",
    "    pi_behavior_train, pi_behavior_test = pi_behavior[train_test_split], pi_behavior[~train_test_split]\n",
    "    pi_evaluation_train, pi_evaluation_test = pi_evaluation[train_test_split], pi_evaluation[~train_test_split]\n",
    "\n",
    "    tau = true_value(Y_matrix_test, pi_evaluation_test, N_test)\n",
    "\n",
    "    for idx_alpha in  range(len(alphas)):    \n",
    "        alpha = alphas[idx_alpha]\n",
    "        pi_behavior, pi_evaluation  = behavior_and_evaluation_policy(X, Y, train_test_split, classes, alpha=alpha)\n",
    "\n",
    "        perm = np.random.permutation(N_train)\n",
    "\n",
    "        X_seq_train, Y_matrix_seq_train, pi_behavior_seq_train, pi_evaluation_seq_train = X_train[perm], Y_matrix_train[perm], pi_behavior_train[perm], pi_evaluation_train[perm]\n",
    "\n",
    "        Y_historical_matrix = np.zeros(shape=(N_train, len(classes)))\n",
    "        A_historical_matrix = np.zeros(shape=(N_train, len(classes)))\n",
    "\n",
    "        for i in range(N_train):\n",
    "            a = np.random.choice(classes, p=pi_behavior[i])\n",
    "            Y_historical_matrix[i, a] = 1\n",
    "            A_historical_matrix[i, a] = 1\n",
    "            \n",
    "        #IPW3 estimator\n",
    "        res_ipw3 = ipw(Y_historical_matrix, X_seq_train, X_test, classes, pi_evaluation_train, A_hst=A_historical_matrix)\n",
    "        #Direct method estimator\n",
    "        res_dm = dm(Y_historical_matrix, X_seq_train, X_test, pi_evaluation_test, classes)\n",
    "        #DML with L1\n",
    "        res_dml1 =dml(Y_historical_matrix, A_historical_matrix, X_seq_train, X_test, pi_evaluation_seq_train, pi_evaluation_test, classes, pi_behavior=pi_behavior_seq_train, method='Lasso')\n",
    "        #DML with L2\n",
    "        res_dml2 =dml(Y_historical_matrix, A_historical_matrix, X_seq_train, X_test, pi_evaluation_seq_train, pi_evaluation_test, classes, pi_behavior=pi_behavior_seq_train, method='Ridge')\n",
    "\n",
    "        print(res_ipw3)\n",
    "        print(res_dm)\n",
    "        print(res_dr1)\n",
    "        print(res_dr2)\n",
    "        print(res_dml1_truew)\n",
    "        print(res_dml2_truew)\n",
    "        \n",
    "        res_ipw3_list[trial, idx_alpha] = res_ipw3\n",
    "        res_dm_list[trial, idx_alpha] = res_dm\n",
    "        res_dr1_list[trial, idx_alpha] = res_dr1\n",
    "        res_dr2_list[trial, idx_alpha] = res_dr2\n",
    "        res_dml1_truew_list[trial, idx_alpha] = res_dml1_truew\n",
    "        res_dml2_truew_list[trial, idx_alpha] = res_dml2_truew\n",
    "        \n",
    "        np.savetxt(\"exp_results/res_ipw3.csv\", res_ipw3_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_dm.csv\", res_dm_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_dr1.csv\", res_dr1_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_dr2.csv\", res_dr2_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_dml1.csv\", res_dml1_truew_list, delimiter=\",\")\n",
    "        np.savetxt(\"exp_results/res_dml2.csv\", res_dml2_truew_list, delimiter=\",\")\n",
    "        \n",
    "    tau_list[trial] = tau\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs_ope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
